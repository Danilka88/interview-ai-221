# Модуль LLM-провайдеров (LLM Providers Module)

Этот модуль предоставляет функциональность для подключения и управления различными провайдерами больших языковых моделей (LLM), включая локальные (Ollama) и сторонние API (OpenAI, YandexGPT, Sber GigaChat).

**Важное примечание:** Этот модуль разработан как полностью независимый блок. Он не изменяет и не влияет на существующий функционал приложения, который использует LLM (например, голосовое собеседование, симуляция, конструктор вакансий). Если вы хотите использовать LLM из этого модуля в других частях приложения, вам потребуется реализовать соответствующую интеграцию через его API.

## Структура модуля

- `base_llm.py`: Определяет абстрактный базовый класс для всех LLM-провайдеров, обеспечивая единый интерфейс.
- `ollama_llm.py`: Реализация провайдера для локальных моделей Ollama.
- `openai_llm.py`: Реализация провайдера для OpenAI API.
- `yandex_llm.py`: Реализация провайдера для YandexGPT API (с заглушкой, если нет прямой интеграции LangChain).
- `sber_llm.py`: Реализация провайдера для Sber GigaChat API (с заглушкой, если нет прямой интеграции LangChain).
- `llm_selector.py`: Центральный компонент для выбора активного LLM-провайдера на основе настроек.
- `config.py`: Управляет настройками LLM-провайдеров (выбранный провайдер, API ключи).
- `api.py`: Реализует FastAPI эндпоинты для управления настройками LLM, тестирования соединения и генерации текста через API/Webhook.
- `settings.html`: HTML-страница для пользовательского интерфейса, позволяющего настраивать параметры LLM-провайдеров.

## Функциональность

- **Выбор провайдера**: Позволяет выбрать активный LLM-провайдер (Ollama, OpenAI, YandexGPT, Sber GigaChat).
- **Управление API ключами**: Предоставляет поля для ввода и сохранения API ключей для сторонних сервисов.
- **Тестирование соединения**: Возможность проверить корректность настроек и соединения с выбранным провайдером.
- **API для генерации текста**: Эндпоинт (`POST /api/v1/llm-providers/generate`) для синхронной генерации текста с использованием выбранного LLM.
- **Webhook для генерации текста**: Эндпоинт (`POST /api/v1/llm-providers/webhook/generate`) для асинхронной генерации текста с обратным вызовом по вебхуку.

## Использование

1.  **Доступ к настройкам**: Откройте страницу `/llm-providers/settings` в вашем браузере, чтобы настроить параметры LLM-провайдеров.
2.  **Использование API**: Для генерации текста используйте эндпоинты `POST /api/v1/llm-providers/generate` (для синхронной генерации) или `POST /api/v1/llm-providers/webhook/generate` (для асинхронной генерации с вебхуком).

## Зависимости

Для работы модуля необходимы следующие Python-библиотеки (помимо базовых LangChain):

- `langchain-openai` (для OpenAI)
- `yandex-gpt` (если используется YandexGPT, может потребоваться установка через `pip install yandex-gpt`)
- `gigachat-client` (если используется Sber GigaChat, может потребоваться установка через `pip install gigachat-client`)

Убедитесь, что они установлены (`pip install -r requirements.txt`).

## Расширение

Модуль разработан таким образом, чтобы его можно было легко расширять новой функциональностью LLM (например, добавление новых провайдеров, поддержка различных типов моделей) без влияния на остальную часть приложения.